{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba8d29cc-0c72-4123-8d3c-d10eeaffc546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "809408ce-4ad2-42ff-a1ab-9894601a5a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_X_SIZE = 320\n",
    "IMG_Y_SIZE = 240\n",
    "EPOCHS = 25\n",
    "NUM_FEATURES = 1024\n",
    "MAX_SEQ_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b70fe88-b910-44f3-967e-63ad58012f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>path</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>arrest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>blast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>deliberate damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>firing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>road accident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>theft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>arrest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>blast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               path  \\\n",
       "0           0  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...   \n",
       "1           1  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...   \n",
       "2           2  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...   \n",
       "3           3  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...   \n",
       "4           4  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...   \n",
       "5           5  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...   \n",
       "6           6  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...   \n",
       "7           7  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...   \n",
       "8           8  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...   \n",
       "9           9  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...   \n",
       "\n",
       "            category  \n",
       "0             arrest  \n",
       "1             attack  \n",
       "2              blast  \n",
       "3  deliberate damage  \n",
       "4             firing  \n",
       "5      road accident  \n",
       "6              theft  \n",
       "7             arrest  \n",
       "8             attack  \n",
       "9              blast  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df = pd.read_csv('sampled_50.csv')\n",
    "train_data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55021c53-485b-4220-8120-a8f5a51e1803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>path</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>arrest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>blast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>deliberate damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>firing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>road accident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>theft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>arrest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>blast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               path  \\\n",
       "0           0  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...   \n",
       "1           1  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...   \n",
       "2           2  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...   \n",
       "3           3  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...   \n",
       "4           4  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...   \n",
       "5           5  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...   \n",
       "6           6  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...   \n",
       "7           7  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...   \n",
       "8           8  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...   \n",
       "9           9  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...   \n",
       "\n",
       "            category  \n",
       "0             arrest  \n",
       "1             attack  \n",
       "2              blast  \n",
       "3  deliberate damage  \n",
       "4             firing  \n",
       "5      road accident  \n",
       "6              theft  \n",
       "7             arrest  \n",
       "8             attack  \n",
       "9              blast  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter = ['arrest', 'attack', 'blast', 'deliberate damage', 'firing', 'road accident', 'theft']\n",
    "train_filtered_df = train_data_df[train_data_df['category'].isin(filter)]\n",
    "train_filtered_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1210f5d-08aa-4af5-8bf3-ecb86b47e0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>arrest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>blast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>deliberate damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>firing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>road accident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>theft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>arrest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...</td>\n",
       "      <td>blast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path           category\n",
       "0  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...             arrest\n",
       "1  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...             attack\n",
       "2  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...              blast\n",
       "3  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...  deliberate damage\n",
       "4  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...             firing\n",
       "5  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...      road accident\n",
       "6  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...              theft\n",
       "7  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...             arrest\n",
       "8  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...             attack\n",
       "9  C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\C...              blast"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filtered_df.reset_index(drop=True, inplace=True)\n",
    "train_filtered_df.drop(columns='Unnamed: 0', inplace=True)\n",
    "train_filtered_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "441304fd-0152-4e6b-af8e-e41b910f1a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from natsort import natsorted\n",
    "\n",
    "def load_video(path):\n",
    "    frames = []\n",
    "    samples = natsorted(os.listdir(path))\n",
    "    # print(samples)\n",
    "    for sample in samples:\n",
    "        imgpath = os.fsencode(path +'\\\\'+ os.fsdecode(sample))\n",
    "        img = load_img(imgpath)\n",
    "        frames.append(np.asarray(img))\n",
    "    return (np.asarray(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c5902cd-d5ab-439e-9261-845a34bbc2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "29084464/29084464 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "def build_feature_extractor():\n",
    "    feature_extractor = tf.keras.applications.DenseNet121(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_Y_SIZE, IMG_X_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = tf.keras.applications.inception_v3.preprocess_input\n",
    "\n",
    "    inputs = tf.keras.Input((IMG_Y_SIZE, IMG_X_SIZE, 3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "\n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return tf.keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
    "\n",
    "\n",
    "feature_extractor = build_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "192a1560-b481-4518-9008-a7a81e790148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arrest', 'attack', 'blast', 'deliberate damage', 'firing', 'road accident', 'theft']\n"
     ]
    }
   ],
   "source": [
    "label_processor = tf.keras.layers.StringLookup(\n",
    "    num_oov_indices=0, vocabulary=np.unique(train_filtered_df[\"category\"])\n",
    ")\n",
    "print(label_processor.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d708a1ae-a77f-425e-8d88-8524fae84dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_all_videos(df):\n",
    "    num_samples = len(df)\n",
    "    video_paths = df[\"path\"].values.tolist()\n",
    "    labels = df[\"category\"].values\n",
    "    labels = label_processor(labels[..., None]).numpy()\n",
    "\n",
    "    #frame features to be learned\n",
    "    frame_features = np.zeros(\n",
    "        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "    )\n",
    "\n",
    "    # For each video.\n",
    "    for idx, path in enumerate(video_paths):\n",
    "        # Gather all its frames and add a batch dimension.\n",
    "        print(\"loading video from path:\", path)\n",
    "        frames = load_video(path)\n",
    "        \n",
    "                # Pad shorter videos.\n",
    "        if len(frames) != 0 and len(frames) < MAX_SEQ_LENGTH:\n",
    "            diff = MAX_SEQ_LENGTH - len(frames)\n",
    "            padding = np.zeros((diff, IMG_Y_SIZE, IMG_X_SIZE, 3), dtype=\"float32\")\n",
    "            frames = np.concatenate((frames, padding))\n",
    "        \n",
    "        frames = frames[None, ...]\n",
    "\n",
    "        # Initialize placeholders to store features of the current video.\n",
    "        temp_frame_features = np.zeros(\n",
    "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "        )\n",
    "\n",
    "        # Extract features from the frames of the current video.\n",
    "        for i, batch in enumerate(frames):\n",
    "            video_length = batch.shape[0]\n",
    "            length = min(MAX_SEQ_LENGTH, video_length)\n",
    "            for j in range(length):\n",
    "                if np.mean(batch[j, :]) > 0.0:\n",
    "                    temp_frame_features[i, j, :] = feature_extractor.predict(\n",
    "                        batch[None, j, :],\n",
    "                        verbose=0\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "                    temp_frame_features[i, j, :] = 0.0\n",
    "\n",
    "        frame_features[idx,] = temp_frame_features.squeeze()\n",
    "\n",
    "    return frame_features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d0cd0027-9de6-4bf6-b327-f22aa7fd9645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading video from path: C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\Crime Dataset\\train\\arrest\\video_4\n",
      "loading video from path: C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\Crime Dataset\\train\\attack\\video_98\n",
      "loading video from path: C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\Crime Dataset\\train\\blast\\video_12\n",
      "loading video from path: C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\Crime Dataset\\train\\deliberate damage\\video_3\n",
      "loading video from path: C:\\Development\\Code\\JupyterProjects\\MLBuzz22\\Crime Dataset\\train\\firing\\video_22\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# try smaller subset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m train_filtered_df \u001b[38;5;241m=\u001b[39m train_filtered_df[:\u001b[38;5;241m14\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m train_data, train_labels \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_all_videos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_filtered_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36mprepare_all_videos\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(length):\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(batch[j, :]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m---> 37\u001b[0m         temp_frame_features[i, j, :] \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_extractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m         temp_frame_features[i, j, :] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\mlai_tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\mlai_tf\\lib\\site-packages\\keras\\engine\\training.py:2249\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2247\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_predict_begin()\n\u001b[0;32m   2248\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, iterator \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():  \u001b[38;5;66;03m# Single epoch.\u001b[39;00m\n\u001b[0;32m   2250\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m   2251\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\mlai_tf\\lib\\site-packages\\keras\\engine\\data_adapter.py:1307\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1305\u001b[0m \u001b[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[1;32m-> 1307\u001b[0m     data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1308\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epochs):\n\u001b[0;32m   1309\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\mlai_tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:499\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 499\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    501\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    502\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\mlai_tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:696\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    694\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 696\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\mlai_tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:721\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(ds_variant):\n\u001b[0;32m    717\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    718\u001b[0m       gen_dataset_ops\u001b[38;5;241m.\u001b[39manonymous_iterator_v3(\n\u001b[0;32m    719\u001b[0m           output_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types,\n\u001b[0;32m    720\u001b[0m           output_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_shapes))\n\u001b[1;32m--> 721\u001b[0m   \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\mlai_tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3408\u001b[0m, in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   3407\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3408\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3409\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3411\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# try smaller subset\n",
    "train_filtered_df = train_filtered_df[:14]\n",
    "train_data, train_labels = prepare_all_videos(train_filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b71a3cd3-5679-4b4e-82fe-973c6777b0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame features in train set: (14, 512, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Frame features in train set: {train_data.shape}\")\n",
    "np.save('densenet_sample_2_features_train0', train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "660d9bbe-1a69-4c1d-9861-d5c7aef7da1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]] 14\n"
     ]
    }
   ],
   "source": [
    "#override labels\n",
    "labels = train_filtered_df['category'].values\n",
    "labels = label_processor(labels[..., None]).numpy()\n",
    "train_labels = labels\n",
    "print(labels, len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deac7a0b-7198-426a-ac45-bf49c3615d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomize extraction\n",
    "size = len(train_data)\n",
    "shuffle_idx = np.arange(size)\n",
    "np.random.shuffle(shuffle_idx)\n",
    "print(shuffle_idx)\n",
    "\n",
    "train_data_shuffled = train_data[shuffle_idx]\n",
    "train_labels_shuffled = train_labels[shuffle_idx]\n",
    "print(train_data_shuffled)\n",
    "print(train_labels_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "624074e2-36ab-4dee-9da1-b6d3fa90c86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=output_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # The inputs are of shape: `(batch_size, frames, num_features)`\n",
    "        length = tf.shape(inputs)[1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return inputs + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        mask = tf.reduce_any(tf.cast(inputs, \"bool\"), axis=-1)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a25e0af8-6629-426e-a416-74e5267e4204",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim, dropout=0.3\n",
    "        )\n",
    "        self.dense_proj = tf.keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=tf.nn.gelu), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "\n",
    "        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2dd3bc7-1b49-4bc2-a732-d863ded146a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model():\n",
    "    sequence_length = MAX_SEQ_LENGTH\n",
    "    embed_dim = NUM_FEATURES\n",
    "    dense_dim = 4\n",
    "    num_heads = 1\n",
    "    classes = len(label_processor.get_vocabulary())\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(None, None))\n",
    "    x = PositionalEmbedding(\n",
    "        sequence_length, embed_dim, name=\"frame_position_embedding\"\n",
    "    )(inputs)\n",
    "    x = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"transformer_layer\")(x)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(classes, activation=\"softmax\")(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d59c4995-e23c-42a7-993c-54f1364e3f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(start, end, loadmodel=False):\n",
    "    # filepath = \"/tmp/video_classifier\"\n",
    "    # checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    #     filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
    "    # )\n",
    "    \n",
    "    if loadmodel:\n",
    "        #load model\n",
    "        seq_model = tf.keras.models.load_model('xformer_video_identifier')\n",
    "        print('Loaded model xformer_video_identifier')\n",
    "    else:\n",
    "        seq_model = get_compiled_model()\n",
    "        print('Generated model graph')\n",
    "    \n",
    "    #partition to handle GPU memory\n",
    "    print(\"Training from \", start, \"to \", end)\n",
    "    train_data_part = train_data[start:end]\n",
    "    train_labels_part = train_labels[start:end]\n",
    "\n",
    "    model = get_compiled_model()\n",
    "    history = model.fit(\n",
    "        train_data_part,\n",
    "        train_labels_part,\n",
    "        validation_split=0.15,\n",
    "        epochs=EPOCHS,\n",
    "        # callbacks=[checkpoint],\n",
    "    )\n",
    "\n",
    "    # model.load_weights(filepath)\n",
    "    # _, accuracy = model.evaluate(test_data, test_labels)\n",
    "    # print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    model.save('xformer_video_identifier')\n",
    "    print(\"Saved model xformer_video_identifier\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4111acf0-dbd2-47fb-a4d1-ebe4f6fa66a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "467cc3b9-db56-4d0f-ac0a-4419d6561abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated model graph\n",
      "Training from  0 to  14\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - 3s 3s/step - loss: 6.4911 - accuracy: 0.1818 - val_loss: 6.0520 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 6.3038 - accuracy: 0.2727 - val_loss: 8.0259 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 7.2818 - accuracy: 0.0909 - val_loss: 6.9969 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 4.3179 - accuracy: 0.2727 - val_loss: 5.5118 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 3.7382 - accuracy: 0.2727 - val_loss: 5.0002 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 2.0585 - accuracy: 0.4545 - val_loss: 4.1126 - val_accuracy: 0.3333\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 2.4813 - accuracy: 0.3636 - val_loss: 4.6905 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 2.0025 - accuracy: 0.5455 - val_loss: 5.0097 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 2.3719 - accuracy: 0.4545 - val_loss: 5.2229 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 2.6965 - accuracy: 0.4545 - val_loss: 5.0802 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 1.3911 - accuracy: 0.6364 - val_loss: 4.8512 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 2.0037 - accuracy: 0.4545 - val_loss: 4.7112 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 1.3308 - accuracy: 0.3636 - val_loss: 4.8201 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 1.6361 - accuracy: 0.4545 - val_loss: 5.1276 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 1.3870 - accuracy: 0.7273 - val_loss: 5.5964 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 1.1454 - accuracy: 0.5455 - val_loss: 6.0801 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 1.1488 - accuracy: 0.6364 - val_loss: 6.5166 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.6725 - accuracy: 0.7273 - val_loss: 6.8242 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 1.0125 - accuracy: 0.6364 - val_loss: 6.9678 - val_accuracy: 0.3333\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.2770 - accuracy: 1.0000 - val_loss: 7.1882 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.5592 - accuracy: 0.8182 - val_loss: 7.4693 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.8920 - accuracy: 0.5455 - val_loss: 7.7252 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.1726 - accuracy: 1.0000 - val_loss: 8.0503 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.5894 - accuracy: 0.7273 - val_loss: 8.2079 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.7580 - accuracy: 0.8182 - val_loss: 8.1332 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_4_layer_call_fn, embedding_4_layer_call_and_return_conditional_losses, multi_head_attention_4_layer_call_fn, multi_head_attention_4_layer_call_and_return_conditional_losses, layer_normalization_6_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: xformer_video_identifier\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: xformer_video_identifier\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model xformer_video_identifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SP\\miniconda3\\envs\\mlai_tf\\lib\\site-packages\\keras\\engine\\functional.py:1563: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\SP\\miniconda3\\envs\\mlai_tf\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    }
   ],
   "source": [
    "trained_model = run_experiment(0, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed1525d3-0241-458a-9a48-3c37b7a7a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predict(start, end, model):\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "    results = model.predict(train_data[start:end])\n",
    "    # print(results)\n",
    "    for result in results:\n",
    "        print(\"---------------------------------\")\n",
    "        for i in np.argsort(result)[::-1]:\n",
    "            print(f\" {class_vocab[i]}: {result[i] * 100:5.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d21379b7-895e-4706-93bb-b3884bb4bf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 639ms/step\n",
      "---------------------------------\n",
      " arrest: 96.62%\n",
      " blast:  1.13%\n",
      " attack:  0.96%\n",
      " firing:  0.78%\n",
      " road accident:  0.29%\n",
      " deliberate damage:  0.21%\n",
      " theft:  0.00%\n",
      "---------------------------------\n",
      " attack: 58.93%\n",
      " arrest: 20.87%\n",
      " blast: 10.09%\n",
      " firing:  7.61%\n",
      " deliberate damage:  1.89%\n",
      " road accident:  0.61%\n",
      " theft:  0.00%\n",
      "---------------------------------\n",
      " blast: 46.34%\n",
      " arrest: 43.93%\n",
      " attack:  6.13%\n",
      " road accident:  1.82%\n",
      " firing:  1.08%\n",
      " deliberate damage:  0.70%\n",
      " theft:  0.00%\n",
      "---------------------------------\n",
      " deliberate damage: 72.87%\n",
      " attack:  9.13%\n",
      " arrest:  8.39%\n",
      " firing:  5.76%\n",
      " blast:  3.44%\n",
      " road accident:  0.40%\n",
      " theft:  0.00%\n",
      "---------------------------------\n",
      " firing: 64.24%\n",
      " attack: 20.08%\n",
      " arrest:  9.99%\n",
      " blast:  2.54%\n",
      " deliberate damage:  2.11%\n",
      " road accident:  1.05%\n",
      " theft:  0.00%\n",
      "---------------------------------\n",
      " road accident: 87.24%\n",
      " arrest: 10.49%\n",
      " firing:  1.04%\n",
      " blast:  0.86%\n",
      " deliberate damage:  0.19%\n",
      " attack:  0.18%\n",
      " theft:  0.00%\n",
      "---------------------------------\n",
      " theft: 99.99%\n",
      " blast:  0.01%\n",
      " arrest:  0.00%\n",
      " attack:  0.00%\n",
      " firing:  0.00%\n",
      " deliberate damage:  0.00%\n",
      " road accident:  0.00%\n"
     ]
    }
   ],
   "source": [
    "test_predict(0, 7, trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f6ce7a-aa9a-4a19-bb07-9f2a0c5d9cec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
